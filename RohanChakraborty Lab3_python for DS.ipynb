{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "collapsed_sections": [
        "f8617014",
        "8fe1a778",
        "7d65d16b",
        "1052145a",
        "46e2fdc1",
        "3a523216",
        "5d0eccca",
        "20ca20d0",
        "1d2a9878",
        "a731fc61",
        "d06850aa",
        "e991aa01",
        "32f97c6f",
        "8ea8dd55",
        "bdb30aab",
        "862b277c"
      ],
      "name": "Supervised Learning - Lab Session - Sample Solution.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "VuYWX6yleVeo",
      "cell_type": "markdown",
      "source": "# Sample Solution\n",
      "metadata": {
        "id": "VuYWX6yleVeo"
      }
    },
    {
      "id": "fcbd582c",
      "cell_type": "markdown",
      "source": "## Learning Outcomes\n- Exploratory data analysis & preparing the data for model building. \n- Machine Learning - Supervised Learning Classification\n  - Logistic Regression\n  - Naive bayes Classifier\n  - KNN Classifier\n  - Decision Tree Classifier\n  - Random Forest Classifier\n  - Ensemble methods\n- Training and making predictions using different classification models.\n- Model evaluation",
      "metadata": {
        "id": "fcbd582c"
      }
    },
    {
      "id": "f2e961f9",
      "cell_type": "markdown",
      "source": "## Objective: \n- The Classification goal is to predict “heart disease” in a person with regards to different factors given. \n\n## Context:\n- Heart disease is one of the leading causes of death for people of most races in the US. At least 1 of 3 key risk factors for heart disease: high blood pressure, high cholesterol, and smoking. \n- Detecting and preventing the factors that have the greatest impact on heart disease is very important in healthcare. Machine learning methods may detect \"patterns\" from the data and can predict whether a patient is suffering from any heart disease or not..\n\n## Dataset Information\n\n#### Source: https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease?datasetId=1936563&sortBy=voteCount\nOriginally, the dataset come from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of U.S. residents. \n\nThis dataset consists of eighteen columns\n- HeartDisease: Respondents that have ever reported having coronary heart disease (CHD) or myocardial infarction (MI)\n- BMI: Body Mass Index (BMI)\n- Smoking: smoked at least 100 cigarettes in your entire life\n- AlcoholDrinking: Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week\n- Stroke:Ever had a stroke?\n- PhysicalHealth: physical health, which includes physical illness and injury\n- MentalHealth: for how many days during the past 30 days was your mental health not good?\n- DiffWalking: Do you have serious difficulty walking or climbing stairs?\n- Sex: male or female?\n- AgeCategory: Fourteen-level age category\n- Race: Imputed race/ethnicity value\n- Diabetic: diabetes?\n- PhysicalActivity: Adults who reported doing physical activity or exercise during the past 30 days other than their regular job\n- GenHealth: Would you say that in general your health is good, fine or excellent?\n- SleepTime: On average, how many hours of sleep do you get in a 24-hour period?\n- Asthma: you had asthma?\n- KidneyDisease: Not including kidney stones, bladder infection or incontinence, were you ever told you had kidney disease?\n- SkinCancer: Ever had skin cancer?",
      "metadata": {
        "id": "f2e961f9"
      }
    },
    {
      "id": "f8617014",
      "cell_type": "markdown",
      "source": "### 1. Importing Libraries",
      "metadata": {
        "id": "f8617014"
      }
    },
    {
      "id": "e0b0b6ab",
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier",
      "metadata": {
        "id": "e0b0b6ab",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8fe1a778",
      "cell_type": "markdown",
      "source": "### 2. Load the dataset and display a sample of five rows of the data frame.",
      "metadata": {
        "id": "8fe1a778"
      }
    },
    {
      "id": "lhAe9IZxBD40",
      "cell_type": "code",
      "source": "#from google.colab import drive\n#drive.mount('/content/drive')\n#df = pd.read_csv('/content/drive/MyDrive/heart_data.csv')",
      "metadata": {
        "id": "lhAe9IZxBD40",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "l9XqZkTqVi4_",
      "cell_type": "code",
      "source": "df = pd.read_csv('heart_data.csv')\ndf.head()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "executionInfo": {
          "elapsed": 413,
          "status": "ok",
          "timestamp": 1655549650830,
          "user": {
            "displayName": "Ranjitha Prasad",
            "userId": "10570177482505539876"
          },
          "user_tz": -330
        },
        "id": "l9XqZkTqVi4_",
        "outputId": "06e1dda9-5e04-4067-ead3-78de3e61da93",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7d65d16b",
      "cell_type": "markdown",
      "source": "### 3. Check the shape of the data (number of rows and columns). Check the general information about the dataframe using the .info() method.",
      "metadata": {
        "id": "7d65d16b"
      }
    },
    {
      "id": "844c36e6",
      "cell_type": "code",
      "source": "## Lets check the shape\ndf.shape",
      "metadata": {
        "id": "844c36e6",
        "outputId": "177c8837-df49-4c3c-97ca-8ee85861ba89",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5e59b172",
      "cell_type": "code",
      "source": "## Lets check basic information of the data\ndf.info()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 422,
          "status": "ok",
          "timestamp": 1655549707657,
          "user": {
            "displayName": "Ranjitha Prasad",
            "userId": "10570177482505539876"
          },
          "user_tz": -330
        },
        "id": "5e59b172",
        "outputId": "2a07cb32-76f9-451d-efd0-28104ad1d807",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9d4be9a5",
      "cell_type": "markdown",
      "source": "- The output shows that we have around 319795 entries with 18 columns. \n- We have 14 object type data and 4 float type data",
      "metadata": {
        "id": "9d4be9a5"
      }
    },
    {
      "id": "1052145a",
      "cell_type": "markdown",
      "source": "### 4. Check the statistical summary of the dataset and write your inferences.",
      "metadata": {
        "id": "1052145a"
      }
    },
    {
      "id": "5df66600",
      "cell_type": "code",
      "source": "## Lets check the statistical summary of the bumerical data\ndf.describe().T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "executionInfo": {
          "elapsed": 401,
          "status": "ok",
          "timestamp": 1655549751344,
          "user": {
            "displayName": "Ranjitha Prasad",
            "userId": "10570177482505539876"
          },
          "user_tz": -330
        },
        "id": "5df66600",
        "outputId": "4efd27ec-9dd4-46c2-b6b8-488f0c7b62fb",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9100fc51",
      "cell_type": "code",
      "source": "## Lets check the statistical summary of the categorical data\ndf.describe(include='O')",
      "metadata": {
        "id": "9100fc51",
        "outputId": "a1f7983f-16c1-4c0b-aff6-d00b46d8c653",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "23e80b31",
      "cell_type": "markdown",
      "source": "- The minimum value of the BMI is around 12 and maximum is 94.85\n- The mental health indicates that for how many days during the past 30 days was your mental health not good, so that minimum value 0 means the person's mental health was good throughout the month whereas on an average it is 7 days that mental health was not good. \n- HeartDisease, Smoking, Alcohol Drinking, Stroke, DiffWalking, Sex, PhysicalActivity, Asthma, KidneyDisease, and SkinCancer columns contain the binary categories 'Yes' or 'NO'.\n- There are 6 different race category.",
      "metadata": {
        "id": "23e80b31"
      }
    },
    {
      "id": "46e2fdc1",
      "cell_type": "markdown",
      "source": "### 5. Check the percentage of missing values in each column of the data frame. Drop the missing values if there are any.",
      "metadata": {
        "id": "46e2fdc1"
      }
    },
    {
      "id": "209f6435",
      "cell_type": "code",
      "source": "# Checking missing values in each colunms\ndf.isnull().sum()/len(df)*100",
      "metadata": {
        "id": "209f6435",
        "outputId": "8167a227-d59d-4633-ff0f-d6cb7ce3f6ff",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c95d3277",
      "cell_type": "markdown",
      "source": "- There are no missing values in the dataset.",
      "metadata": {
        "id": "c95d3277"
      }
    },
    {
      "id": "3a523216",
      "cell_type": "markdown",
      "source": "### 6. Check if there are any duplicate rows. If any drop them and check the shape of the dataframe after dropping duplicates.",
      "metadata": {
        "id": "3a523216"
      }
    },
    {
      "id": "c0869572",
      "cell_type": "code",
      "source": "len(df[df.duplicated()])",
      "metadata": {
        "id": "c0869572",
        "outputId": "f9f2bf79-00d5-4438-ab0b-a12ab758dc56",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9e068f25",
      "cell_type": "markdown",
      "source": "- There are around 18K duplicate record, lets drop them.",
      "metadata": {
        "id": "9e068f25"
      }
    },
    {
      "id": "11bcd7e9",
      "cell_type": "code",
      "source": "## dropping duplicates\ndf.drop_duplicates(inplace=True)",
      "metadata": {
        "id": "11bcd7e9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "999d5277",
      "cell_type": "code",
      "source": "## checking the shape after dropping duplicates\ndf.shape",
      "metadata": {
        "id": "999d5277",
        "outputId": "838d11e0-109d-4d7f-abad-54b02b240e8d",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5d0eccca",
      "cell_type": "markdown",
      "source": "### 7. Check the distribution of the target variable (i.e. 'HeartDisease') and write your observations.",
      "metadata": {
        "id": "5d0eccca"
      }
    },
    {
      "id": "a8790409",
      "cell_type": "code",
      "source": "## Let's check the count of target variable\ndf['HeartDisease'].value_counts().plot(kind='pie',autopct='%1.0f%%')\nplt.show()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "executionInfo": {
          "elapsed": 682,
          "status": "ok",
          "timestamp": 1655446442181,
          "user": {
            "displayName": "V. Arun Kumar",
            "userId": "02991517788843717529"
          },
          "user_tz": -330
        },
        "id": "a8790409",
        "outputId": "f65a2f0e-fb50-4836-c5d4-e47f621dcc8c",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e926c2e6",
      "cell_type": "markdown",
      "source": "- We can observe that the target class distribution is highly imbalanced.",
      "metadata": {
        "id": "e926c2e6"
      }
    },
    {
      "id": "20ca20d0",
      "cell_type": "markdown",
      "source": "### 8. Visualize the distribution of the target column 'heart disease' with respect to various categorical features and write your observations.",
      "metadata": {
        "id": "20ca20d0"
      }
    },
    {
      "id": "a2e41b9a",
      "cell_type": "code",
      "source": "### Categorical features in the dataset\ncategorical_features = df.select_dtypes(include=[np.object])\ncategorical_features.columns",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 367,
          "status": "ok",
          "timestamp": 1655550161776,
          "user": {
            "displayName": "Ranjitha Prasad",
            "userId": "10570177482505539876"
          },
          "user_tz": -330
        },
        "id": "a2e41b9a",
        "outputId": "f07538fb-a05c-4dbd-e8c8-eb1c207751ed",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "48a4d3ab",
      "cell_type": "markdown",
      "source": "##### Let's look at the distribution of the number of people with heart disease from various factors",
      "metadata": {
        "id": "48a4d3ab"
      }
    },
    {
      "id": "dea82c0c",
      "cell_type": "code",
      "source": "i = 1\nplt.figure(figsize = (30,25))\nfor feature in categorical_features:\n    plt.subplot(6,3,i)\n    sns.countplot(x = feature,hue = 'HeartDisease' , data = df)\n    i +=1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "executionInfo": {
          "elapsed": 8212,
          "status": "ok",
          "timestamp": 1655550181866,
          "user": {
            "displayName": "Ranjitha Prasad",
            "userId": "10570177482505539876"
          },
          "user_tz": -330
        },
        "id": "dea82c0c",
        "outputId": "8ef49295-2752-4a84-cd90-c03e7ec9f65a",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "72b8c047",
      "cell_type": "markdown",
      "source": "- From the plot we can observe that:\n- People who smoke have higher chances of heart diesease than non smokers.\n- Male are more prone to suffer from heart diseases as compared to females.\n- People with age limit in between 55-75 has higher chances of getting heart diseases.\n- If person has difficulty in walking or climbing stairs there is a high probability that he or she is suffering from some heart disease.\n- There are higher chances of a person having heart disease if he does not have any kidney disease.",
      "metadata": {
        "id": "72b8c047"
      }
    },
    {
      "id": "1d2a9878",
      "cell_type": "markdown",
      "source": "### 9. Check the unique categories in the column 'Diabetic'. Replace 'Yes (during pregnancy)' as 'Yes' and 'No, borderline diabetes' as 'No'.",
      "metadata": {
        "id": "1d2a9878"
      }
    },
    {
      "id": "805e88d2",
      "cell_type": "code",
      "source": "## let check unique categories in column 'Diabetic'\ndf['Diabetic'].unique()",
      "metadata": {
        "id": "805e88d2",
        "outputId": "c95c4bfd-3fee-4dac-82a2-1a8a6ccdc874",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3af12c95",
      "cell_type": "code",
      "source": "df['Diabetic'] = df['Diabetic'].replace({'Yes (during pregnancy)':'Yes','No, borderline diabetes':'No'})",
      "metadata": {
        "id": "3af12c95",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "abe7cdcd",
      "cell_type": "code",
      "source": "## recheck\ndf['Diabetic'].value_counts()",
      "metadata": {
        "id": "abe7cdcd",
        "outputId": "d476fdd3-1d02-4e76-b5cb-3ca2b4a44310",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a731fc61",
      "cell_type": "markdown",
      "source": "### 10. For the target column 'HeartDiease', Replace 'No' as 0 and 'Yes' as 1. ",
      "metadata": {
        "id": "a731fc61"
      }
    },
    {
      "id": "61d122c9",
      "cell_type": "code",
      "source": "## Replacing \"No\" as 0 and \"Yes\" as 1\ndf['HeartDisease'] = df['HeartDisease'].replace({'Yes':1,'No':0})",
      "metadata": {
        "id": "61d122c9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6044e1f0",
      "cell_type": "code",
      "source": "## lets check\ndf['HeartDisease'].value_counts()",
      "metadata": {
        "id": "6044e1f0",
        "outputId": "ccbf1348-a561-4a90-ea74-680541e4964f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d06850aa",
      "cell_type": "markdown",
      "source": "### 11. Label Encode the columns \"AgeCategory\", \"Race\", and \"GenHealth\". Encode the rest of the columns using dummy encoding approach.",
      "metadata": {
        "id": "d06850aa"
      }
    },
    {
      "id": "525986e3",
      "cell_type": "code",
      "source": "## Label Encoding categorical variables using \"AgeCategory\", \"Race\", and \"GenHealth\" label encoder\n\n## select object datatype variables\nobject_type_variables = [i for i in df[['AgeCategory','Race','GenHealth']] if df.dtypes[i] == object]\nobject_type_variables \n\n\nle = LabelEncoder()\n\ndef encoder(df):\n    for i in object_type_variables:\n        q = le.fit_transform(df[i].astype(str))  \n        df[i] = q                               \n        df[i] = df[i].astype(int)\nencoder(df)",
      "metadata": {
        "id": "525986e3",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9a7b1393",
      "cell_type": "code",
      "source": "## Dummy encoding the rest of the columns, since they have binary entries. 'Yes' or 'No'\ndf = pd.get_dummies(df,drop_first=True)",
      "metadata": {
        "id": "9a7b1393",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a0849daf",
      "cell_type": "code",
      "source": "## let check few samples after encoding.\ndf.head(2)",
      "metadata": {
        "scrolled": true,
        "id": "a0849daf",
        "outputId": "ab04a583-be8d-4dd4-8bdb-823a515d6fd0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e991aa01",
      "cell_type": "markdown",
      "source": "### 12. Store the target column (i.e.'HeartDisease') in the y variable and the rest of the columns in the X variable.",
      "metadata": {
        "id": "e991aa01"
      }
    },
    {
      "id": "977652b9",
      "cell_type": "code",
      "source": "## Lets store the target column in the Y variable and the rest of the columns in the X variable.\nX = df.drop('HeartDisease',axis=1)\ny = df['HeartDisease']",
      "metadata": {
        "id": "977652b9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "32f97c6f",
      "cell_type": "markdown",
      "source": "### 13. Split the dataset into two parts (i.e. 70% train and 30% test) and print the shape of the train and test data",
      "metadata": {
        "id": "32f97c6f"
      }
    },
    {
      "id": "7be616a7",
      "cell_type": "code",
      "source": "## train_test_split() is used to divide dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nprint(X_train.shape,X_test.shape)\nprint(y_train.shape,y_test.shape)",
      "metadata": {
        "id": "7be616a7",
        "outputId": "435d6812-25f1-474e-c7e8-da5974b84664",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8ea8dd55",
      "cell_type": "markdown",
      "source": "### 14. Standardize the numerical columns using Standard Scalar approach for both train and test data.",
      "metadata": {
        "id": "8ea8dd55"
      }
    },
    {
      "id": "cbb45096",
      "cell_type": "code",
      "source": "## Standardizing only numerical columns. (not standardizing the dummy encoded data)\nss = StandardScaler()\n\nX_train.iloc[:,:7] = ss.fit_transform(X_train.iloc[:,:7])\nX_test.iloc[:,:7] = ss.transform(X_test.iloc[:,:7])",
      "metadata": {
        "id": "cbb45096",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8f25bbdf",
      "cell_type": "code",
      "source": "## Lets check few scaled features\nX_train.head(2)",
      "metadata": {
        "id": "8f25bbdf",
        "outputId": "718b7df6-a30f-46a4-d2c0-7166a21ebf65",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "57386022",
      "cell_type": "code",
      "source": "X_test.head(2)",
      "metadata": {
        "id": "57386022",
        "outputId": "b885ec05-3648-4750-9702-86e85fe8c73f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bdb30aab",
      "cell_type": "markdown",
      "source": "### 15. Write a function.\n- i) Which can take the model and data as inputs.\n- ii) Fits the model with the train data.\n- iii) Makes predictions on the test set.\n- iv) Returns the Accuracy Score.",
      "metadata": {
        "id": "bdb30aab"
      }
    },
    {
      "id": "b6138f02",
      "cell_type": "code",
      "source": "def fit_n_print(model, X_train, X_test, y_train, y_test):  # take the model, and data as inputs\n\n    model.fit(X_train, y_train)   # fits the model with the train data\n\n    pred = model.predict(X_test)  # makes predictions on the test set\n\n    accuracy = accuracy_score(y_test, pred)\n                   \n    return accuracy  # return all the metrics",
      "metadata": {
        "id": "b6138f02",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "862b277c",
      "cell_type": "markdown",
      "source": "### 16. Use the function and train a Logistic regression, KNN, Naive Bayes, Decision tree, Random Forest, Adaboost, GradientBoost, and Stacked Classifier models and make predictions on test data and evaluate the models, compare and write your conclusions and steps to be taken in future in order to improve the accuracy of the model.",
      "metadata": {
        "id": "862b277c"
      }
    },
    {
      "id": "6556977d",
      "cell_type": "code",
      "source": "## Intializing the models\n\nlr = LogisticRegression()\nnb = GaussianNB()\nknn = KNeighborsClassifier()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nadb = AdaBoostClassifier()\ngb = GradientBoostingClassifier()\n\nestimators = [('rf', rf),('knn', knn), ('gb', gb), ('adb', adb)]\nsc = StackingClassifier(estimators=estimators, final_estimator=rf)",
      "metadata": {
        "id": "6556977d",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8addbbbd",
      "cell_type": "code",
      "source": "result = pd.DataFrame(columns = ['Accuracy'])\n\nfor model, model_name in zip([lr, nb, knn, dt, rf, adb, gb, sc], \n                             ['Logistic Regression','Naive Bayes','KNN','Decision tree', \n                              'Random Forest', 'Ada Boost', 'Gradient Boost', 'Stacking']):\n    \n    result.loc[model_name] = fit_n_print(model, X_train, X_test, y_train, y_test)",
      "metadata": {
        "id": "8addbbbd",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f90db9ec",
      "cell_type": "code",
      "source": "result",
      "metadata": {
        "id": "f90db9ec",
        "outputId": "a661172f-8b11-4c0e-c0c9-9a1638283234",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "K5f-IKPLV3bN",
      "cell_type": "markdown",
      "source": "### Conclusion",
      "metadata": {
        "id": "K5f-IKPLV3bN"
      }
    },
    {
      "id": "eI26tvitV9Yg",
      "cell_type": "markdown",
      "source": "- From EDA:-\n  - People who smoke have higher chances of heart diesease than no smokers\n  - Male are more prone to suffer from heart diseases as compared to females\n  - People with age limit in between 55-75 has higher chances of getting heart diseases\n  - If person has difficulty in walking or climbing stairs there is a high probability that he or she is suffering from some heart disease\n  - There are higher chances of a person having heart disease if he does not have any kidney disease.\n- From Model:-\n  - We see that the best performing models are Gradient Boost, Adaboost,Logistic Regression and KNN with around 91% accuracy.\n  - Please note that the target class is highly imbalanced So, accuracy does not holds good for imbalanced data. Accuracy becomes poor measure of evaluation for our classification model in this context.\n  - We can further go with evaluating the models based on the different performance metrics such as presicion, recall and F1score and choose the model accordingly.\n  - Further we can apply sampling techniques and try to balance the data and build models based on that data will increase our model performance, Kindly refer to this link to know how deal with imbalanced data https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/\n  - Also, we can tune the hyperparameters and find the best set of hyperparameters and building the models based on those will increase the classification performance of the model.",
      "metadata": {
        "id": "eI26tvitV9Yg"
      }
    },
    {
      "id": "515596d0",
      "cell_type": "markdown",
      "source": "----\n## Happy Learning:)\n----",
      "metadata": {
        "id": "515596d0"
      }
    }
  ]
}